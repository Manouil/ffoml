{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "\n",
    "# Load the pre-trained model\n",
    "loaded_model = load_model('./models/cnn_std')\n",
    "\n",
    "# Define dimensions\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "# Choose an intermediate convolutional layer for deep dreaming\n",
    "deep_dream_model = Model(inputs=loaded_model.input, outputs=loaded_model.layers[2].output)\n",
    "\n",
    "# Define the loss function\n",
    "def compute_loss(input_image):\n",
    "    activation = deep_dream_model(input_image)\n",
    "    # Use the full activation of a specific channel if slicing is not feasible\n",
    "    filter_activation = activation[..., 1]\n",
    "    return tf.reduce_mean(filter_activation)\n",
    "\n",
    "# Define gradient ascent step\n",
    "@tf.function\n",
    "def gradient_ascent_step(img, learning_rate):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(img)\n",
    "        loss = compute_loss(img)\n",
    "    grads = tape.gradient(loss, img)\n",
    "    grads = tf.math.l2_normalize(grads)\n",
    "    img += learning_rate * grads\n",
    "    return loss, img\n",
    "\n",
    "# Visualize a filter using gradient ascent\n",
    "def visualize_filter():\n",
    "    iterations = 30  # Adjust as needed\n",
    "    learning_rate = 1.0  # Lower learning rate for stability\n",
    "    img = tf.random.uniform((1, img_width, img_height, 1))  # Random starting image\n",
    "    for iteration in range(iterations):\n",
    "        loss, img = gradient_ascent_step(img, learning_rate)\n",
    "\n",
    "    return loss, img\n",
    "\n",
    "# Run the visualization\n",
    "loss, img = visualize_filter()\n",
    "\n",
    "# Normalize and display the resulting dream image\n",
    "printable_img = img[0]\n",
    "printable_img = (printable_img - tf.reduce_min(printable_img)) / (tf.reduce_max(printable_img) - tf.reduce_min(printable_img))\n",
    "plt.imshow(printable_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the trained model (replace with your actual model path)\n",
    "model = cnn_std\n",
    "\n",
    "# Define the Deep Dream function\n",
    "def deep_dream(input_image, target_class, dream_model, iterations=30, step=1.0):\n",
    "    input_image = tf.Variable(np.expand_dims(input_image, axis=0), dtype=tf.float32)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(input_image)\n",
    "            predictions = dream_model(input_image)\n",
    "            loss = tf.reduce_mean(predictions[:, :, :, target_class])  # Focus on target class\n",
    "\n",
    "        grads = tape.gradient(loss, input_image)\n",
    "        grads /= (tf.math.reduce_std(grads) + 1e-8)  # Normalize gradients\n",
    "        input_image.assign_add(step * grads)  # Update the image\n",
    "\n",
    "    return input_image.numpy()[0]\n",
    "\n",
    "# Specify the layers you want to visualize\n",
    "layer_names = [\"conv2d_2\"]  # Replace with your layer names\n",
    "dream_images = {}\n",
    "\n",
    "# Generate Deep Dream images for classes 2 and 9\n",
    "for layer_name in layer_names:\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    dream_model = Model(inputs=model.input, outputs=layer_output)\n",
    "\n",
    "    for target_class in [2, 9]:\n",
    "        base_image = np.random.random((28, 28))  # Random noise as starting image\n",
    "        dream_image = deep_dream(base_image, target_class=target_class, dream_model=dream_model)\n",
    "        dream_images[(layer_name, target_class)] = dream_image\n",
    "\n",
    "# Plot all images\n",
    "fig, axes = plt.subplots(len(layer_names), 2, figsize=(10, 15))\n",
    "\n",
    "for i, layer_name in enumerate(layer_names):\n",
    "    for j, target_class in enumerate([2, 9]):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(dream_images[(layer_name, target_class)], cmap=\"viridis\")\n",
    "        ax.set_title(f\"Class {target_class}, Layer: {layer_name}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"deep_dream_digits.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffoml8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
