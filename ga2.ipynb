{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "\n",
    "x_train, x_test = x_train/127.5 - 1, x_test/127.5 - 1\n",
    "\n",
    "nb_features = np.prod(x_train.shape[1:])\n",
    "\n",
    "x_train.resize((n_train, nb_features))\n",
    "x_test.resize((n_test, nb_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Data visualisation (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "x_train_pca = pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for digit in range(10):  # Loop over 10 classes\n",
    "    plt.scatter(x_train_pca[y_train == digit, 0], x_train_pca[y_train == digit, 1], label=f'Class {digit}', alpha=0.7)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # Ensure unique labels\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.title('PCA of Dataset with 10 Classes')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pairs = list(combinations(range(10), 2))\n",
    "\n",
    "# Create subplots for all class pairs\n",
    "fig, axes = plt.subplots(len(class_pairs) // 7 + (len(class_pairs) % 7 != 0), 7, figsize=(8, 8))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (class1, class2) in enumerate(class_pairs):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot data points for the two classes\n",
    "    ax.scatter(x_train_pca[y_train == class1, 0], x_train_pca[y_train == class1, 1], alpha=0.7, s=10, label=f'Class {class1}')\n",
    "    ax.scatter(x_train_pca[y_train == class2, 0], x_train_pca[y_train == class2, 1], alpha=0.7, s=10, label=f'Class {class2}')\n",
    "    \n",
    "    ax.set_title(f'{class1} vs {class2}', fontsize=6)\n",
    "    ax.set_aspect('equal')  # Make each plot square-shaped\n",
    "    ax.set_xticks([])  # Remove x-axis ticks\n",
    "    ax.set_yticks([])  # Remove y-axis ticks\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "# Remove any empty subplots if number of plots is not a perfect multiple of columns\n",
    "for idx in range(len(class_pairs), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "# Adjust layout for minimal white space\n",
    "plt.subplots_adjust(wspace= 0.02, hspace=0.33)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why is PCA a good option to visualise data?\n",
    "* Add plots to your report and discuss your observations.\n",
    "* Which classes can be linearly separated?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_pairs(digit1, digit2):\n",
    "    cond = (y_train==digit1) + (y_train==digit2)\n",
    "    binary_x_train = x_train[cond, :]\n",
    "    binary_y_train = y_train[cond].astype(int)\n",
    "    binary_y_train[binary_y_train == digit1] = -1\n",
    "    binary_y_train[binary_y_train == digit2] = 1\n",
    "    return binary_x_train, binary_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_x_train, binary_y_train = digit_pairs(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_X_pca = pca.fit_transform(binary_x_train)\n",
    "\n",
    "plt.figure(figsize=(5, 3.5))\n",
    "for digit in [-1, 1]:  # Loop over 10 classes\n",
    "    plt.scatter(binary_X_pca[binary_y_train == digit, 0], binary_X_pca[binary_y_train == digit, 1], label=f'Class {digit}', alpha=0.7)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # Ensure unique labels\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.title('PCA of Dataset with 10 Classes')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Perceptrons (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    weighted_sum = np.dot(x, w)\n",
    "    result = 1 if weighted_sum > b else -1\n",
    "    return result\n",
    "\n",
    "def optimize(x, y):\n",
    "    iteration = 0\n",
    "    error = np.inf\n",
    "    m, n = x.shape\n",
    "    w = np.random.uniform(-1, 1, n)\n",
    "    b = np.random.uniform(-1, 1)\n",
    "    learning_rate = 0.002\n",
    "    while (iteration <= 1000) & (error > 1e-3):\n",
    "        error = 0\n",
    "        fp, fn = 0, 0\n",
    "        predictions  = []\n",
    "        for sample, target in zip(x, y):\n",
    "            prediction = predict(sample, w, b)\n",
    "            predictions.append(prediction)\n",
    "            if prediction != target:\n",
    "                if prediction > target:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "                error = error + 1\n",
    "                w = w + learning_rate*(target-prediction)*sample\n",
    "                b = b + learning_rate*(target-prediction)\n",
    "\n",
    "        iteration += 1        \n",
    "        print(\"Iteration:\", iteration, 'with error:', error, fp, fn)\n",
    "    return predictions\n",
    "\n",
    "binary_x_train, binary_y_train = digit_pairs(1, 7)\n",
    "preds = optimize(binary_x_train, binary_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(preds, binary_y_train):\n",
    "    if i[0] != i[1]:\n",
    "        print(i)\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = binary_x_train[8].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_y_train[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_digit(sample_no):\n",
    "    digit = sample_no.reshape(28, 28)\n",
    "\n",
    "    plt.imshow(digit, cmap='gray')  # Use 'gray' colormap for grayscale images\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels = np.argsort(y_train)\n",
    "x_train_sorted = x_train[sorted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_digit(x_train_sorted[59999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.2148 - accuracy: 0.9362 - val_loss: 0.1168 - val_accuracy: 0.9650\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.1023 - val_accuracy: 0.9688\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0489 - accuracy: 0.9841 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 0.0821 - val_accuracy: 0.9764\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1056 - val_accuracy: 0.9732\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0977 - accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train/255\n",
    "y_train = np.eye(10)[y_train]\n",
    "X_test = X_test/ 255\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "X_train.resize((n_train, nb_features))\n",
    "X_test.resize((n_test, nb_features))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1000, input_shape=(X_test.shape[1],), activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,          # Log weight histograms every epoch\n",
    "    write_graph=True,          # Log the computation graph\n",
    "    write_images=True,         # Log model weights as images\n",
    "    update_freq='epoch'        # How often to write logs (defaults to every batch)\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=5,               # Number of epochs\n",
    "                    batch_size=128,           # Batch size\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tensorboard_callback])     # Split some of the data for validation\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 23s 58ms/step - loss: 0.2277 - accuracy: 0.9293 - val_loss: 0.1441 - val_accuracy: 0.9574\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0988 - accuracy: 0.9711 - val_loss: 0.1234 - val_accuracy: 0.9653\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0670 - accuracy: 0.9803 - val_loss: 0.1030 - val_accuracy: 0.9712\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.0500 - accuracy: 0.9849 - val_loss: 0.1010 - val_accuracy: 0.9707\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0408 - accuracy: 0.9879 - val_loss: 0.1212 - val_accuracy: 0.9723\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.1014 - accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(1000, input_shape=(X_test.shape[1],), activation='relu'))\n",
    "model2.add(Dense(3000, activation='relu'))\n",
    "model2.add(Dense(1000, activation='relu'))\n",
    "model2.add(Dense(500, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,          # Log weight histograms every epoch\n",
    "    write_graph=True,          # Log the computation graph\n",
    "    write_images=True,         # Log model weights as images\n",
    "    update_freq='epoch'        # How often to write logs (defaults to every batch)\n",
    ")\n",
    "\n",
    "history = model2.fit(X_train, y_train, \n",
    "                    epochs=5,               # Number of epochs\n",
    "                    batch_size=128,           # Batch size\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tensorboard_callback])     # Split some of the data for validation\n",
    "\n",
    "test_loss, test_acc = model2.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffoml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
