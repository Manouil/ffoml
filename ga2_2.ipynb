{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset, normalise it to [-1, 1] and flatten it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "\n",
    "# normalise to [-1, 1] so that PCA is not swayed by features with bigger value ranges.\n",
    "x_train, x_test = x_train/127.5 - 1, x_test/127.5 - 1\n",
    "\n",
    "# each pixel is a feature. num of pixels = height x width\n",
    "nb_features = np.prod(x_train.shape[1:])\n",
    "\n",
    "x_train.resize((n_train, nb_features))\n",
    "x_test.resize((n_test, nb_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Data visualisation (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whe can perform PCA since data is already standardised\n",
    "pca = PCA(n_components=2)\n",
    "x_train_pca = pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "# Plot all classes iteratively, on same plot\n",
    "for digit in range(10):\n",
    "    plt.scatter(x_train_pca[y_train == digit, 0], x_train_pca[y_train == digit, 1], label=f'Class {digit}', alpha=0.7)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles)) \n",
    "\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "plt.title('PCA of Dataset with 10 Classes')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a general idea of the whole dataset but we have to to brake it into smaller part in order to understand it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all pairs of classes\n",
    "class_pairs = list(combinations(range(10), 2))\n",
    "\n",
    "# set up plot table shape\n",
    "fig, axes = plt.subplots(len(class_pairs) // 5 + (len(class_pairs) % 5 != 0), 5, figsize=(5, 8.5))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "total_sil_score = 0\n",
    "\n",
    "# for all pairs of digits, take their pca data that we calculated before, plot them and get their silhouette score\n",
    "for idx, (class1, class2) in enumerate(class_pairs):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    cond = (y_train == class1) + (y_train == class2)\n",
    "    x_train_pca_bin = x_train_pca[cond, :]\n",
    "    y_train_pca_bin = y_train[cond] * 1\n",
    "\n",
    "    y_train_pca_bin = np.where(y_train_pca_bin == class1, -1, 1)\n",
    "\n",
    "    # this calculates the similarity of the cluster's samples which gives a hint to their separability. \n",
    "    # Values range from [0 to 1] for datasets with no misclassifications. Higher is better\n",
    "    sil_score = silhouette_score(x_train_pca_bin, y_train_pca_bin)\n",
    "    total_sil_score += sil_score\n",
    "    \n",
    "    # plot first and second component, for one class and then the other\n",
    "    ax.scatter(x_train_pca_bin[y_train_pca_bin == -1, 0], x_train_pca_bin[y_train_pca_bin == -1, 1], alpha=0.7, s=10, label=f'Class {class1}')\n",
    "    ax.scatter(x_train_pca_bin[y_train_pca_bin == 1, 0], x_train_pca_bin[y_train_pca_bin == 1, 1], alpha=0.7, s=10, label=f'Class {class2}')\n",
    "    \n",
    "    # Making plot less cluttered\n",
    "    ax.set_title(f'{class1} vs {class2}', fontsize=6)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "# Remove empty subplots\n",
    "for idx in range(len(class_pairs), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "# Reuce white space\n",
    "plt.subplots_adjust(wspace= 0.02, hspace=0.33)\n",
    "plt.show()\n",
    "\n",
    "print('Average silhouette score is:', round(total_sil_score/len(class_pairs), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No pair of classes seems easily seperable. We will perform PCA in pairs in order to reduce the noise and influence of other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that accepts two digits and returns the corresponding slices of train data and labels\n",
    "def digit_pairs(x, y, digit1, digit2):\n",
    "    if digit1 == digit2:\n",
    "        print('Same digit given twice')\n",
    "        raise ValueError\n",
    "    \n",
    "    cond = (y==digit1) + (y==digit2)\n",
    "    x_binary = x[cond, :]\n",
    "    y_binary = y[cond].astype(int)\n",
    "    y_binary = np.where(y_binary == digit1, -1, 1)\n",
    "\n",
    "    return x_binary, y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before, but now PCA is done on each slice of digit pairs, individually\n",
    "class_pairs = list(combinations(range(10), 2))\n",
    "\n",
    "fig, axes = plt.subplots(len(class_pairs) // 5 + (len(class_pairs) % 5 != 0), 5, figsize=(4.5, 8))\n",
    "fig.patch.set_facecolor('lightblue')\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "total_sil_score = 0\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "for idx, (class1, class2) in enumerate(class_pairs):\n",
    "    ax = axes[idx]\n",
    "    x_train_bin, y_train_bin = digit_pairs(x_train, y_train, class1, class2)\n",
    "    x_train_bin_pca = pca2.fit_transform(x_train_bin)\n",
    "\n",
    "    sil_score = silhouette_score(x_train_bin_pca, y_train_bin)\n",
    "    total_sil_score += sil_score\n",
    "    \n",
    "    # Plot\n",
    "    ax.scatter(x_train_bin_pca[y_train_bin == -1, 0], x_train_bin_pca[y_train_bin == -1, 1], alpha=0.7, s=10, label=f'Class {class1}')\n",
    "    ax.scatter(x_train_bin_pca[y_train_bin == 1, 0], x_train_bin_pca[y_train_bin == 1, 1], alpha=0.7, s=10, label=f'Class {class2}')\n",
    "    \n",
    "    # Making plot less cluttered\n",
    "    ax.set_title(f'{class1} vs {class2}', fontsize=6)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "# Remove empty subplots\n",
    "for idx in range(len(class_pairs), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "# Reuce white space\n",
    "plt.subplots_adjust(wspace= 0.02, hspace=0.33)\n",
    "plt.show()\n",
    "\n",
    "print('Average silhouette score is:', round(total_sil_score/len(class_pairs), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the silhouette score has increased, indicating that the samples of each class are better formed than before. Indeed, a visual inspection reveals that most pairs now seem more easily seperable. No pair appears perfectly linearily seperable but a lot (3,4), (3,7), (6, 9) appear more distinct. This concludes Part 1. Next, we will try to train a perceptron to be able to seperate two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Perceptrons (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a perceptron can be broken down into two components: 1) getting the output of the perceptron and 2) using that output to guide the update of its parameters.\n",
    "\n",
    "The way a perceptron or a neuron works, is that it receives an arbitary number of inputs/stimulations $x = [x_1, x_2, ...]$. These inputs are scaled by a similarily sized weight vector $w^T = [w_1, w_2, ...]$. Thats the perceptron's way of assigning an importance and meaning to each input. Finaly, the sum of the weighted inputs is compared agains a threshold $b$, and a decision is taken based on the result. This serves the puprose if intruducing a non-linearity which mimics the way decisions are often made. (e.g, the higher the temperatuer the more likely it is people will go for a swim, but going for a swim is a binary situation as people generaly do not travel halfway to the swimming pool because the temperature is halfway to heatwave.)\n",
    "\n",
    "\n",
    "The function `predict(x, w b)` implements these calculations and returns the decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates dot product of input-x with weights-w and compares to threshold. Returns the result of the comparison which is the final decision.\n",
    "def predict(x, w, b):\n",
    "    weighted_sum = np.dot(x, w)\n",
    "    result = 1 if weighted_sum > b else -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step exposed two kinds of parameters of the perceptron that are not given by the dataset: the weight vector $w$ and the threshold or bias $b$. As these can be set arbitarily, the problem of producing a neuron that pefrorms better than a random chooser can be seen as working out a method that modifies the customisable parameters so that the produce the right output.\n",
    "\n",
    "One approach for achieving this is as follows:\\\n",
    "a) get one of the training samples and use it to produce a prediction. If the prediction is correct no action needs to be taken. (In the extreme case where all predictions are correct, modifying the parameters can only make the predictor worse)\\\n",
    "b) if the prediction is wrong, the parameters will be changed with two things in mind: 1. The output must change to the direction of the target label. If the target is $1$ and the prediction was $-1$ then the dot product of the input and the weights must increase so that it grows closer to the target, and vice versa. We can get the direction of desired change with $(target - prediction)$. 2. Of all the parameters of the model_deeper_deeper, the ones that are responsible for the mistake must change the most. Naturally, changing the weights of features that are irrelevant to this misclassification will not helpe prevent it in the future, and could undo the work done on these features. We can scale the change to the neurons weights based on their relevance to the misclassification by multiplying with the sample, as by definition, this sample has high values of the features that correspond to the weights that must be changed.\n",
    "Finaly, a hyperparameter can be used to modify the level of change at each update. Larger values of this learning rate can make initial approach to the local minimum faster but as the distance to it decreases, it can force it to overshoot back and forth above it, preventing improvement. This can be avoided with smaller learning rates at the cost of convergance speed, which must be kept within reasonable times.\n",
    "\n",
    "These form the core of the training logic. The function `optimise(x, y)` prepares the ground for training the perceptron by first randomly initialising its parameters, while also setting up additional parameters for keeping track of the error and the training iteration. \\\n",
    "The model iterates through all of the samples, producing a prediction and adjusting the weights and bias accordingly.\\\n",
    "A termination condition ensures that the algorithm stops upon reaching a satisfying results, or failing to reach one within the specified time frame.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applyis the correction process described above to optimise a given set of parameters w and b\n",
    "def optimize(x, w, b, y):\n",
    "    iteration = 0\n",
    "    mse = np.inf\n",
    "    # found in practice to work well\n",
    "    learning_rate = 0.002\n",
    "    mses = []\n",
    "    while (iteration <= 1000) & (mse > 1e-3):\n",
    "        mse, fp, fn = 0, 0, 0\n",
    "        predictions  = []\n",
    "        for sample, target in zip(x, y):\n",
    "            prediction = predict(sample, w, b)\n",
    "            predictions.append(prediction)\n",
    "            if prediction != target:\n",
    "                if prediction > target:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "                w = w + learning_rate*(target-prediction)*sample\n",
    "                # the theshold for the dot product is not scaled based on the input, so no *sample\n",
    "                b = b + learning_rate*(target-prediction)\n",
    "\n",
    "        iteration += 1\n",
    "        # average of squared error\n",
    "        mse = sum((predictions - y)**2)/len(y)\n",
    "        mses.append(mse)\n",
    "        accuracy = round(np.sum(predictions == y)/len(y), 4)\n",
    "        print(\"Iteration:\", iteration, 'with MSE:', round(mse, 4), ', Accuracy:', accuracy, ', False positives:', fp, ', False Negatives:', fn)\n",
    "\n",
    "    return predictions, w, b, accuracy, mses\n",
    "\n",
    "# wraps around optimise to provide randomly initialised parameters and the data related to the two digits of interest\n",
    "def init_and_train(x, y, digit1, digit2):\n",
    "    x_train_binary, y_train_binary = digit_pairs(x, y, digit1, digit2)\n",
    "    m, n = x_train_binary.shape\n",
    "    w = np.random.uniform(-1, 1, n)\n",
    "    b = np.random.uniform(-1, 1)\n",
    "    \n",
    "    return optimize(x_train_binary, w, b, y_train_binary)\n",
    "\n",
    "preds, weights, bias, accuracy, mses = init_and_train(x_train, y_train, 8, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of MSE vs number of iteration\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(mses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSEs')\n",
    "plt.title('Plot of Mean Square Classification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used the model to produce prediction for the test samples, which allows for the test data accuracy to be calculated\n",
    "def test_data_check(x, y, digit1, digit2, weights, bias):\n",
    "    x_test_binary, y_test_binary = digit_pairs(x, y, digit1, digit2)\n",
    "    predictions = []\n",
    "    for sample in x_test_binary:\n",
    "        predictions.append(predict(sample, weights, bias))\n",
    "\n",
    "    accuracy = round(np.sum(predictions == y_test_binary)/len(y_test_binary), 4)\n",
    "    mse = sum((predictions - y_test_binary)**2)/len(y)\n",
    "    return accuracy, mse\n",
    "\n",
    "print(test_data_check(x_test, y_test, 8, 9, weights, bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can edit the optimise function to keep track of the test MSE throughout the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(x, w, b, y):\n",
    "    iteration = 0\n",
    "    mse = np.inf\n",
    "    learning_rate = 0.002\n",
    "    mses = []\n",
    "    test_mses = []\n",
    "    while (iteration <= 1000) & (mse > 1e-3):\n",
    "        mse, fp, fn = 0, 0, 0\n",
    "        predictions  = []\n",
    "        for sample, target in zip(x, y):\n",
    "            prediction = predict(sample, w, b)\n",
    "            predictions.append(prediction)\n",
    "            if prediction != target:\n",
    "                if prediction > target:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "                w = w + learning_rate*(target-prediction)*sample\n",
    "                b = b + learning_rate*(target-prediction)\n",
    "\n",
    "        iteration += 1\n",
    "        mse = sum((predictions - y)**2)/len(y)\n",
    "        mses.append(mse)\n",
    "        # track mse for test dataset as well\n",
    "        _, test_mse = test_data_check(x_test, y_test, 8, 9, w, b)\n",
    "        test_mses.append(test_mse)\n",
    "        accuracy = round(np.sum(predictions == y)/len(y), 4)\n",
    "        print(\"Iteration:\", iteration, 'with MSE:', round(mse, 4), ', Accuracy:', accuracy, ', False positives:', fp, ', False Negatives:', fn)\n",
    "\n",
    "    return predictions, w, b, accuracy, mses, test_mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, weights, bias, accuracy, mses, test_mses = init_and_train(x_train, y_train, 8, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of the classifier we need to know the balance of the classes. Below we plot the class distribution for train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_counts = Counter(y_train)\n",
    "y_test_counts = Counter(y_test)\n",
    "\n",
    "axis_points = sorted(set(y_train_counts.keys()).union(y_test_counts.keys()))\n",
    "\n",
    "frequencies1 = [y_train_counts[item] for item in axis_points]\n",
    "frequencies2 = [y_test_counts[item] for item in axis_points]\n",
    "\n",
    "bar_width = 0.4\n",
    "\n",
    "r1 = [x - bar_width/2 for x in range(len(axis_points))]\n",
    "r2 = [x + bar_width/2 for x in range(len(axis_points))]\n",
    "\n",
    "plt.bar(r1, frequencies1, width=bar_width, color='skyblue', label='Train')\n",
    "plt.bar(r2, frequencies2, width=bar_width, color='orange', label='Lest')\n",
    "plt.xticks(range(len(axis_points)), axis_points)\n",
    "plt.xlabel(\"Digit\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Training and Test Histogram\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the classes are close to an equal representation, thus the baseline accuracy and MSE are $10\\%$ and $1/10*(2^2)*(10-1) = 3.6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_counts = Counter(y_train)\n",
    "y_test_counts = Counter(y_test)\n",
    "\n",
    "all_items = sorted(set(y_train_counts.keys()).union(y_test_counts.keys()))\n",
    "\n",
    "frequencies1 = [y_train_counts[item] for item in all_items]\n",
    "frequencies2 = [y_test_counts[item] for item in all_items]\n",
    "\n",
    "bar_width = 0.4\n",
    "\n",
    "r1 = [x - bar_width/2 for x in range(len(all_items))]\n",
    "r2 = [x + bar_width/2 for x in range(len(all_items))]\n",
    "\n",
    "plt.bar(r1, frequencies1, width=bar_width, color='skyblue', label='List 1')\n",
    "plt.bar(r2, frequencies2, width=bar_width, color='salmon', label='List 2')\n",
    "plt.xticks(range(len(all_items)), all_items)\n",
    "plt.xlabel(\"Items\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Overlayed Histogram of Two Lists\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of train dataset MSE against test dataset MSE vs number of iteration\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(mses)\n",
    "plt.plot(test_mses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSEs')\n",
    "plt.title('Plot of Mean Square Classification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that while the training MSE keeps decreasing, the test MSE has its minimus at around the 20 iterations point, after which is starts to slowly climp, suggesting overfitting. Given that, training should be stopped at around 20 iterations.\n",
    "\n",
    "Given that the 2d ndarray `weights` has similar structure with our samples, we can reverse the process that turned them from images to arrays to visualise what our perceptron has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = weights.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_digit(sample_no):\n",
    "    digit = sample_no.reshape(28, 28)\n",
    "\n",
    "    plt.imshow(digit, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_digit(digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, grey values represent pixes towards which the model has learned to be indifferent (like the edges of the image which usually are not enough to differentiate any digits). With high or low brighness are represented pixels that the model has found sway the prediction towards one of the two classes. While not obvious, we can perhaps see how these pixels are part of the handwriten digit for only one of the classes. \\\n",
    "We can see which pixels would make good features for distinguishing of the two classes by calculating the difference between the pixels that are usually part of the one digit and the ones that are usually part of the other digit, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_8 = x_train[y_train == 8]\n",
    "x_9 = x_train[y_train == 9]\n",
    "\n",
    "average_8 = np.mean(x_8, axis=0)\n",
    "average_9 = np.mean(x_9, axis=0)\n",
    "\n",
    "dif = average_8 - average_9\n",
    "print_digit(dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some similarities, at mid-left mostly, but there does not seem to be too much agreement between the two pictures. This is probably due to the fact that the perceptron learns to use whichever pixels help it classify correctly the samples it failes at, so this could be specific pixels for specific samples, not only the ones that are usefull for the general case. Their weights will get high values, even if they are only usefull rarely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eeee prepei na kaneis train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pairs = [random.sample(range(10), 2) for _ in range(5)]\n",
    "accuracies = []\n",
    "for pair in random_pairs:\n",
    "    preds, weights, bias, accuracy, mses, test_mses = init_and_train(x_train, y_train, pair[0], pair[1])\n",
    "    accuracies.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Digit Pair':random_pairs, 'Accuracy':accuracies})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy scores vary depending on the pair. A visual inspection reveals that pairs with similar overal shape or many similar parts have lower accuracy, for the obvious reasons. We could say that the fewer/shorter lines one needs to draw in order to make one digit look like the other, the lower the accuracy score as noise from the hand drawing can more easily create these lines, leading to a misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Multi-Layer Perceptron (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use create a MLP Neural Network with the given architecture specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will perform multiclass classification so we will convert the labels from integers to one-hot encoding, paired with the categorical_crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train/255\n",
    "y_train = np.eye(10)[y_train]\n",
    "X_test = X_test/ 255\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# each pixel is a feature. num of pixels = height x width\n",
    "nb_features = np.prod(X_train.shape[1:])\n",
    "\n",
    "X_train.resize((n_train, nb_features))\n",
    "X_test.resize((n_test, nb_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/Emmts/OneDrive/Desktop/University of Bath/Phase 3 - Unit 9 - Foundations and Frontiers of Machine Learning/FFoML_GA2/logs\\standard\n",
      "Epoch 1/2\n",
      "235/235 [==============================] - 6s 22ms/step - loss: 0.2268 - accuracy: 0.9324 - val_loss: 0.1030 - val_accuracy: 0.9663\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.0769 - accuracy: 0.9767 - val_loss: 0.0762 - val_accuracy: 0.9770\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0762 - accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# We implement the given specifications\n",
    "model.add(Dense(1000, input_shape=(X_test.shape[1],), activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# We will use tensorboard to log the results.\n",
    "log_dir = os.path.join(\"c:/Users/Emmts/OneDrive/Desktop/University of Bath/Phase 3 - Unit 9 - Foundations and Frontiers of Machine Learning/FFoML_GA2/logs\", 'standard')\n",
    "print(log_dir)\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch'\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=2,\n",
    "                    batch_size=256,\n",
    "                    validation_data = (X_test, y_test),     # we do not perform a validation split, instead testing on the test dataset to produce the desired plots\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1000)              785000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice very good results, owning to the almost 2 million parameters. We will test various architectures to draw conclusions about the relations between number of layer, number of neurons and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"c:/Users/Emmts/OneDrive/Desktop/University of Bath/Phase 3 - Unit 9 - Foundations and Frontiers of Machine Learning/FFoML_GA2/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns a TensorBoard object with parameterised location reflecting different architectures\n",
    "def tb_callback_setter(subdir):\n",
    "    log_dir = os.path.join(\"c:/Users/Emmts/OneDrive/Desktop/University of Bath/Phase 3 - Unit 9 - Foundations and Frontiers of Machine Learning/FFoML_GA2/logs\", subdir)\n",
    "\n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "        update_freq='epoch'\n",
    "        )\n",
    "    \n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat the experiment for various depths to investigate how they affect the models characteristics\n",
    "# we reduce the width of the layers to stay within reasonable training times, also with 1000 the model performs well enough so the added layers have no room for improvement\n",
    "def create_and_train(num_of_layers, epochs, learning_rate, batch_size):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(500, input_shape=(X_test.shape[1],), activation='relu'))\n",
    "\n",
    "    for _ in range(num_of_layers - 1):\n",
    "        model.add(Dense(500, activation='relu'))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    tensorboard_callback = tb_callback_setter(f'{num_of_layers}_Layers')\n",
    "\n",
    "    history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    callbacks=[tensorboard_callback])\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    params = model.count_params()\n",
    "\n",
    "    return model, test_acc, test_loss, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1982 - accuracy: 0.9391 - val_loss: 0.1092 - val_accuracy: 0.9665\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0859 - accuracy: 0.9734 - val_loss: 0.0744 - val_accuracy: 0.9757\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0744 - accuracy: 0.9757\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.2101 - accuracy: 0.9372 - val_loss: 0.1209 - val_accuracy: 0.9628\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0946 - accuracy: 0.9712 - val_loss: 0.0896 - val_accuracy: 0.9751\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0896 - accuracy: 0.9751\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 11s 10ms/step - loss: 0.2374 - accuracy: 0.9302 - val_loss: 0.1603 - val_accuracy: 0.9544\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1144 - accuracy: 0.9680 - val_loss: 0.1002 - val_accuracy: 0.9727\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1002 - accuracy: 0.9727\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 13s 12ms/step - loss: 0.2647 - accuracy: 0.9242 - val_loss: 0.1440 - val_accuracy: 0.9616\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1368 - accuracy: 0.9639 - val_loss: 0.1280 - val_accuracy: 0.9694\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1280 - accuracy: 0.9694\n"
     ]
    }
   ],
   "source": [
    "numbers_of_Layers = [3, 4, 6, 8]\n",
    "models = []\n",
    "mlp_accuracies, mlp_losses, mlp_params = [], [], []\n",
    "\n",
    "for layers in numbers_of_Layers:\n",
    "    model, acc, loss, params = create_and_train(layers, 2, 0.001, 64)\n",
    "    models.append(model)\n",
    "    mlp_accuracies.append(acc)\n",
    "    mlp_losses.append(loss)\n",
    "    mlp_params.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "print(f\"Training images {n_train}, Test images {n_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffoml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
